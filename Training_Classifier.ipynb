{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Training-Classifier.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyPbgxwmniCBc/6KDPsJC5FP",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/liranbd1/FaceMaskDetectionLab/blob/main/Training_Classifier.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Installing needed libraries"
      ],
      "metadata": {
        "id": "P3vrmBEpB4KO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install comet_ml"
      ],
      "metadata": {
        "id": "PSPfAzlrB8qG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Connecting to GDrive\n",
        "All of the dataset and saving of the models are stored in GDrive"
      ],
      "metadata": {
        "id": "Z1IgWskUrPjj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive/')"
      ],
      "metadata": {
        "id": "6saC8V7mrPWj",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "89319e62-1d2a-4cb5-e837-a9f8d93519b7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/gdrive/\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Initializing Comet"
      ],
      "metadata": {
        "id": "ni4nFGucCExI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Import comet_ml at the top of your file\n",
        "from comet_ml import Experiment\n",
        "\n",
        "# Create an experiment with your api key\n",
        "experiment = Experiment(\n",
        "    api_key=\"TleaivY1A4bzGtbcYhLmrRyAQ\",\n",
        "    project_name=\"mask-detection\",\n",
        "    workspace=\"liranbd1\",\n",
        ")"
      ],
      "metadata": {
        "id": "1I15ortDCHEF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Imports"
      ],
      "metadata": {
        "id": "e90_4-XLyA5b"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import Dataset\n",
        "import torchvision\n",
        "from torchvision import transforms\n",
        "import pandas as pd\n",
        "from PIL import Image\n",
        "from sklearn.model_selection import train_test_split"
      ],
      "metadata": {
        "id": "O-o6-SJax_0O"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Custom Dataset - FaceMaskDetectionDataset"
      ],
      "metadata": {
        "id": "MFwxf-PDgjMa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class FaceMaskDetectionDataset(Dataset):\n",
        "\n",
        "    def __init__(self, annotations_file, img_dir, transform=None, target_transform=None):\n",
        "        self.dataframe = self.process_df(annotations_file)\n",
        "        self.img_dir = img_dir\n",
        "        self.transform = transform\n",
        "\n",
        "        self.target_transform = target_transform\n",
        "\n",
        "        self.classes = [\"face_with_mask\",\n",
        "                        \"face_no_mask\"]\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.dataframe)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "      # Getting the row of the next image \n",
        "      img_row = self.dataframe.iloc[idx]\n",
        "\n",
        "      # Path to image\n",
        "      img_path = os.path.join(self.img_dir, img_row['name'])\n",
        "      \n",
        "      # Bounding box cordinates \n",
        "      # x -> A coordinate of two points \n",
        "      # y -> A coordinate of two points\n",
        "      # Fixed the names when pulling them here to make it more readable\n",
        "      x1 = img_row['x1']\n",
        "      y1 = img_row['x2']\n",
        "      x2 = img_row['y1']\n",
        "      y2 = img_row['y2']\n",
        "\n",
        "      # Cropping the image to see the face\n",
        "      cropped_img = Image.open(img_path).crop((x1,y1, x2,y2))\n",
        "      label = img_row['classname']\n",
        "\n",
        "      # Applying transforms\n",
        "      if self.transform:\n",
        "        image = self.transform(cropped_img)\n",
        "      if self.target_transform:\n",
        "        label = self.target_transform(label)\n",
        "      label = self.classes.index(label)\n",
        "      return image, label\n",
        "\n",
        "    # Processing the input df, since we are getting multiple rows for the same\n",
        "    # face with classes that are not important for the mask/no mask classifier\n",
        "    def process_df(csv_path):\n",
        "      df = pd.read_csv(csv_path)\n",
        "      df = df.drop(df[(df['classname'] != 'face_other_covering') & (df['classname'] != 'face_no_mask') & (df['classname'] != 'face_with_mask') & (df['classname'] != 'face_with_mask_incorrect')].index) # This section will remove all the rows which their classname is not one of the mentiond here.\n",
        "      df.loc[df['classname'] == 'face_with_mask_incorrect', 'classname'] = 'face_with_mask' # Replace all face_with_mask_incorrect with face_with_mask\n",
        "      df.loc[df['classname'] == 'face_other_covering', 'classname'] = 'face_no_mask' # Replace all face_other_covering with face_with_no_mask\n",
        "      return df"
      ],
      "metadata": {
        "id": "XvpBhfX0t54A"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Util functions"
      ],
      "metadata": {
        "id": "_d-THfcV94hy"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Confusion matrix"
      ],
      "metadata": {
        "id": "38SD6m3r979j"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def confusion(prediction, truth):\n",
        "    \"\"\" Returns the confusion matrix for the values in the `prediction` and `truth`\n",
        "    tensors, i.e. the amount of positions where the values of `prediction`\n",
        "    and `truth` are\n",
        "    - 1 and 1 (True Positive)\n",
        "    - 1 and 0 (False Positive)\n",
        "    - 0 and 0 (True Negative)\n",
        "    - 0 and 1 (False Negative)\n",
        "    \"\"\"\n",
        "\n",
        "    confusion_vector = prediction / truth\n",
        "    # Element-wise division of the 2 tensors returns a new tensor which holds a\n",
        "    # unique value for each case:\n",
        "    #   1     where prediction and truth are 1 (True Positive)\n",
        "    #   inf   where prediction is 1 and truth is 0 (False Positive)\n",
        "    #   nan   where prediction and truth are 0 (True Negative)\n",
        "    #   0     where prediction is 0 and truth is 1 (False Negative)\n",
        "\n",
        "    true_positives = torch.sum(confusion_vector == 1).item()\n",
        "    true_negatives = torch.sum(torch.isnan(confusion_vector)).item()\n",
        "    false_positives = torch.sum(confusion_vector == float('inf')).item()\n",
        "    false_negatives = torch.sum(confusion_vector == 0).item()\n",
        "\n",
        "    return true_positives, true_negatives, false_positives, false_negatives\n"
      ],
      "metadata": {
        "id": "Yz8AeH_Q9658"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Log metrics"
      ],
      "metadata": {
        "id": "u1LEYWvSD1LG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Logging the data into comet for easy save and access\n",
        "def log_data(accuracy, precision, recall, f1, loss, epoch, state = \"train\"):\n",
        "  experiment.log_metric(f'{state}_loss', loss, epoch)\n",
        "  experiment.log_metric(f'{state}_accuracy', accuracy, epoch)\n",
        "  experiment.log_metric(f'{state}_recall', recall, epoch)\n",
        "  experiment.log_metric(f'{state}_precision', precision, epoch)\n",
        "  experiment.log_metric(f'{state}_f1', f1, epoch)\n",
        "  "
      ],
      "metadata": {
        "id": "uWaQg4PgD4lc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Global Parameters\n"
      ],
      "metadata": {
        "id": "zYq4lmA6-PNF"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Hyper Parameters"
      ],
      "metadata": {
        "id": "bdrM7w8J_4Mg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "root = \"/content/gdrive/MyDrive/MaskDetection\"\n",
        "model_save_path = os.path.join(root, \"model.pth\")\n",
        "csv_path = os.path.join(root, \"train.csv\")\n",
        "images_path = os.path.join(root, \"images\")\n",
        "\n",
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "\n",
        "torch.manual_seed(0)\n",
        "\n",
        "transform = transforms.Compose(\n",
        "  [\n",
        "    transforms.Resize((224, 224)),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.RandomHorizontalFlip(p=0.5),\n",
        "    transforms.RandomVerticalFlip(p=0.5),\n",
        "    transforms.RandomGrayscale(p=0.1),\n",
        "    transforms.ColorJitter(brightness=0.1,saturation=0.1,hue=0.25),\n",
        "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
        "  ])\n",
        "\n",
        "target_transform = transforms.ToTensor()\n",
        "\n",
        "\n",
        "dataset = FaceMaskDetectionDataset(csv_path, images_path, transform)\n",
        "\n",
        "\n",
        "classifier = torchvision.models.resnet18(pretrained=True)\n",
        "classifier.fc = nn.Linear(512, 2)\n",
        "classifier.to(device)\n",
        "\n",
        "\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "learning_rate = 0.001\n",
        "epochs = 25\n",
        "batch_size = 4\n",
        "optimizer = optim.SGD(net.parameters(), lr=learning_rate, momentum=0.9)\n",
        "\n",
        "\n",
        "experiment.log_parameters({\n",
        "    \"learning_rate\" : learning_rate,\n",
        "    \"epochs\" : epochs,\n",
        "    \"batch_size\": batch_size\n",
        "})"
      ],
      "metadata": {
        "id": "-R0FnB-b-S1J"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Trainset and Testset dataloaders"
      ],
      "metadata": {
        "id": "A06-do31_6Mk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "trainset, testset = train_test_split(dataset, test_size = 0.2)\n",
        "\n",
        "trainloader = torch.utils.data.DataLoader(trainset, batch_size=batch_size, \n",
        "                                          shuffle=True, num_workers=4)\n",
        "testloader = torch.utils.data.DataLoader(testset, batch_size=batch_size, \n",
        "                                         shuffle=True, num_workers=4)\n"
      ],
      "metadata": {
        "id": "nMMB16-f_z65"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Training Loop"
      ],
      "metadata": {
        "id": "aEl5Lpi_AG8t"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_losses = []\n",
        "test_losses = []\n",
        "patience_counter = 0\n",
        "patience_lvl = 5\n",
        "\n",
        "for epoch in range(epochs):  # loop over the dataset multiple times\n",
        "  train_loss = 0.0\n",
        "  train_tp = 0\n",
        "  train_tn = 0\n",
        "  train_fp = 0\n",
        "  train_fn = 0\n",
        "\n",
        "  for i, data in enumerate(trainloader):\n",
        "    # get the inputs; data is a list of [inputs, labels]\n",
        "    inputs, labels = data\n",
        "    labels = labels.to(cuda)\n",
        "    inputs = inputs.to(cuda)\n",
        "    # zero the parameter gradients\n",
        "    optimizer.zero_grad()\n",
        "\n",
        "    # forward + backward + optimize\n",
        "    outputs = net(inputs)\n",
        "    _, predicted = torch.max(outputs.data, 1)\n",
        "\n",
        "    batch_tp, batch_tn, batch_fp, batch_fn = confusion(predicted, labels)\n",
        "    train_tp += batch_tp\n",
        "    train_tn += batch_tn\n",
        "    train_fp += batch_fp\n",
        "    train_fn += batch_fn\n",
        "\n",
        "    loss = criterion(outputs, labels.to(cuda))\n",
        "    loss.backward()\n",
        "\n",
        "    torch.nn.utils.clip_grad_norm_(net.parameters(), 1.0)\n",
        "\n",
        "    optimizer.step()\n",
        "\n",
        "    train_loss += loss.item()\n",
        "\n",
        "  train_total = train_tp + train_tn + train_fp + train_fn\n",
        "  train_accuracy = (train_tp + train_tn) / (train_total * 1.0)\n",
        "  train_precision = (1.0 * train_tp) / (train_tp + train_fp)\n",
        "  train_recall = (1.0 * train_tp) / (train_tp + train_fn)\n",
        "  train_f1 = 2 / ((1 / train_precision) + (1 / train_recall))\n",
        "  \n",
        "  log_data(train_accuracy, train_percision, \n",
        "           train_recall, train_f1, train_loss/train_total, epoch)\n",
        "  \n",
        "  test_loss = 0.0\n",
        "  test_tp = 0\n",
        "  test_fp = 0\n",
        "  test_tn = 0\n",
        "  test_fn = 0\n",
        "\n",
        "  with torch.no_grad():\n",
        "    for i, data in enumerate(testloader):\n",
        "      # get the inputs; data is a list of [inputs, labels]\n",
        "      inputs, labels = data\n",
        "      labels = labels.to(cuda)\n",
        "      inputs = inputs.to(cuda)\n",
        "\n",
        "      outputs = net(inputs.to(cuda))\n",
        "\n",
        "      _, predicted = torch.max(outputs.data, 1)\n",
        "\n",
        "      true_preds = predicted == labels\n",
        "      false_preds = predicted != labels\n",
        "\n",
        "      batch_tp, batch_tn, batch_fp, batch_fn = confusion(predicted, labels)\n",
        "      test_tp += batch_tp\n",
        "      test_tn += batch_tn\n",
        "      test_fp += batch_fp\n",
        "      test_fn += batch_fn\n",
        "\n",
        "      loss = criterion(outputs, labels.to(cuda))\n",
        "      test_loss += loss.item()\n",
        "\n",
        "  test_total = test_tp + test_tn + test_fp + test_fn\n",
        "  test_accuracy = (test_tp + test_tn) / (test_total * 1.0)\n",
        "  test_precision = (1.0 * test_tp) / (test_tp + test_fp)\n",
        "  test_recall = (1.0 * test_tp) / (test_tp + test_fn)\n",
        "  test_f1 = 2 / ((1 / test_precision) + (1 / test_recall))\n",
        "  test_run_loss = test_loss / test_total\n",
        "\n",
        "  log_data(test_accuracy, test_percision, \n",
        "           test_recall, test_f1, test_run_loss, epoch, \"test\")\n",
        "  \n",
        "  test_losses.append(test_run_loss)\n",
        "\n",
        "\n",
        "  # print statistics\n",
        "  print('[epoch %d][train] loss: %.3f acc: %.3f f1: %.3f || [test] loss: %.3f acc: %.3f f1: %.3f' %\n",
        "        (epoch + 1, train_loss / train_total, train_accuracy, train_f1,\n",
        "                    test_run_loss, test_accuracy, test_f1))\n",
        "\n",
        "  # Early stopping           \n",
        "  if (min(test_losses) > test_run_loss or len(test_losses) == 1):\n",
        "    patience_counter = 0\n",
        "    torch.save(net.state_dict(), model_save_path)\n",
        "  else:\n",
        "    patience_counter += 1\n",
        "    if (patience_counter == patience_lvl):\n",
        "      print(\"Patience level maxed stopping training loop\")\n",
        "      break\n",
        "\n",
        "print('Finished Training')\n"
      ],
      "metadata": {
        "id": "BJrxw5ebAKwU"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}