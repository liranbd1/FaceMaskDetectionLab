{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Mask-Detection-Prod.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyPDkNBIi6StWBic1KWpoI4Z",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/liranbd1/FaceMaskDetectionLab/blob/main/Mask_Detection_Prod.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Installing Missing API's\n",
        "\n",
        "* facenet-pytroch library for MTCNN"
      ],
      "metadata": {
        "id": "jxQMNuDSq6SO"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "thD1OFPoxhbQ"
      },
      "outputs": [],
      "source": [
        "!pip install facenet-pytorch"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Connecting to GDrive\n",
        "All of the dataset and saving of the models are stored in GDrive"
      ],
      "metadata": {
        "id": "Z1IgWskUrPjj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive/')"
      ],
      "metadata": {
        "id": "6saC8V7mrPWj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Imports"
      ],
      "metadata": {
        "id": "e90_4-XLyA5b"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import os\n",
        "from facenet_pytorch.models.mtcnn import MTCNN\n",
        "from PIL import Image\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.patches as patches\n",
        "import matplotlib.image as mpimg\n",
        "import torchvision\n",
        "from torchvision import transforms\n",
        "from IPython.core.display import Math\n",
        "from torch.utils.data import Dataset\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import os.path\n",
        "import torch.optim as optim"
      ],
      "metadata": {
        "id": "O-o6-SJax_0O"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Parameters"
      ],
      "metadata": {
        "id": "_BuyshEByEQo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "device = 'cude' if torch.cuda.is_available() else 'cpu'\n",
        "model_weights_path = \"\"\n",
        "\n",
        "mtcnn_model = MTCNN(keep_all = True).to(device)\n",
        "classifier = OurClassifier().to(device)\n",
        "\n",
        "classifier.load_state_dict(torch.load(model_weights_path))\n",
        "classifier.eval()\n",
        "\n",
        "transformations = transforms.Compose(\n",
        "    [\n",
        "      transforms.Resize((32, 32)),\n",
        "      transforms.ToTensor(),\n",
        "      transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
        "    ])"
      ],
      "metadata": {
        "id": "RCmO5rZcyGWe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Production function\n",
        "\n",
        "Given an image path from the user our program:\n",
        "1. Use MTCNN to detect faces bounding boxes in the image.\n",
        "2. For each bounding box we crop the image and pass the face detect to our classifier.\n",
        "3. Saving the bbox and the output of the classifier.\n",
        "4. Drawing on the original image boxes for the faces we found\n",
        "\n",
        "***Green box*** -> Face with mask \\\n",
        "***Red box*** -> Face without a mask"
      ],
      "metadata": {
        "id": "g73tl7t06x-t"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def classify_img(img_path):\n",
        "  img = Image.open(img_path)\n",
        "  bboxes, probs = mtcnn.detect(img)\n",
        "\n",
        "  if bboxes is None:\n",
        "    print(\"No face detected\")\n",
        "    return\n",
        "  \n",
        "  results = []\n",
        "  for box,prob in zip(bboxes, probs):\n",
        "    \n",
        "    if prob < 0.85:\n",
        "      print(\"Skip probabilty below 85%\")\n",
        "      continue\n",
        "\n",
        "    tuple_box = (cor for cor in box)\n",
        "    face_detected = img.crop(tuple_box)\n",
        "    face_tensor = transformations(face_detected).to(device)\n",
        "    outputs = calssifier(face_tensor)\n",
        "    prediction = torch.argmax(outputs, dim=1)\n",
        "    results.append([box, prediction])\n",
        "\n",
        "  fig, ax = plt.subplot()\n",
        "  ax.imshow(img)\n",
        "    \n",
        "  for result in results:\n",
        "    box, label = result\n",
        "    anchor_point = (box[0], box[1])\n",
        "    w = abs(box[0] - box[2])\n",
        "    h = abs(box[1] - box[3])\n",
        "    edge_color = 'r' if label == 1 else 'g'\n",
        "    rect = patches.Rectangle(anchor_point, w,h , linewidth = 1, edgecolor = edge_color, \n",
        "                             facecolor = 'none')\n",
        "    ax.add_patch(rect)\n",
        "\n",
        "  plt.show()"
      ],
      "metadata": {
        "id": "LGPZr5KSyabz"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}